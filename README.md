# genetic-algorithm-implementation
Hyperparameter Optimization for CNNs using genetic algorithms
## Problem Description
The project aims to explore the applications of various Deep Neural Network Architectures in practical problems and to optimize the process of selecting the proper hyperparameters (Dropout, Hidden Layers, etc.) for these tasks. We propose to carry out this optimization using Evolutionary Algorithms, such as Genetic Algorithms, to eliminate the chances of human error arising from the trial-and-error-based process. Evolutionary algorithms have also been shown to be computationally efficient, and hence, our project aims to see how effectively certain Deep Learning application-based problems can be solved using hyperparameters selected via such techniques.
## Research Literature
- [Xiao, Xueli & Yan, Ming & Basodi, Sunitha & Ji, Chunyan & Pan, Yi. (2020). Efficient Hyperparameter Optimization in Deep Learning Using a Variable Length Genetic Algorithm.](https://arxiv.org/abs/2006.12703)
- [Nurshazlyn Mohd Aszemi and P.D.D Dominic, “Hyperparameter Optimization in Convolutional Neural Network using Genetic Algorithms” International Journal of Advanced Computer Science and Applications(IJACSA), 10(6), 2019. ](http://dx.doi.org/10.14569/IJACSA.2019.0100638)
- [N. Gorgolis, I. Hatzilygeroudis, Z. Istenes and L. –. G. Gyenne, "Hyperparameter Optimization of LSTM Network Models through Genetic Algorithm," 2019 10th International Conference on Information, Intelligence, Systems and Applications (IISA), Patras, Greece, 2019, pp. 1-4, doi: 10.1109/IISA.2019.8900675.](https://www.researchgate.net/publication/337513385_Hyperparameter_Optimization_of_LSTM_Network_Models_through_Genetic_Algorithm)
- [Erden, C. Genetic algorithm-based hyperparameter optimization of deep learning models for PM2.5 time-series prediction. Int. J. Environ. Sci. Technol. 20, 2959–2982 (2023)](https://doi.org/10.1007/s13762-023-04763-6)
- [D. E. Puentes G., C. J. Barrios H. and P. O. A. Navaux, "Hyperparameter Optimization for Convolutional Neural Networks with Genetic Algorithms and Bayesian Optimization," 2022 IEEE Latin American Conference on Computational Intelligence (LA-CCI), Montevideo, Uruguay, 2022, pp. 1-5, doi: 10.1109/LA-CCI54402.2022.9981104.](https://www.researchgate.net/publication/366487783_Hyperparameter_Optimization_for_Convolutional_Neural_Networks_with_Genetic_Algorithms_and_Bayesian_Optimization)

## Research Paper Overview
**Research paper used: [Xiao, Xueli & Yan, Ming & Basodi, Sunitha & Ji, Chunyan & Pan, Yi. (2020). Efficient Hyperparameter Optimization in Deep Learning Using a Variable Length Genetic Algorithm.](https://arxiv.org/abs/2006.12703)**
**Features used in making chromosomes:** 
<p>The main idea is to have an initial population of individuals where each individual is a model represented by a chromosome having values for all hyperparameters. These initial models are all of length 2 ie they have 2 layers which we call layer a and b respectively. The initial individuals represent the generation 0 of phase 0. We have set the number of generations and the number of phases manually. Each phase contains the specified number of generations and each generation has a fixed population size p. At the start of phase 0 we have created the generation 0. We now find out the fitness of each individual in the population and sort them no the basis of fitness. Then we simulate natural selection by only choosing a fixed number of fittest individuals that pass on to the next generation. In addition to this we include some unfit individuals  well as some mutated individuals which pass on to the next generation. Then we choose any two of theses individuals of the older generation and their chromosomes are cross-overed to make new individuals of that geneation to make the population size p. Again we calculate the fitness of all the individuals and perform these operations to go to the next generations.</p>
<p>After the previously decided number of generations within a phase has been reached, we move to the next phase. While moving to the next phase we only take the fittest individual of the previous phase. To make the individuals of the first generation of this phase, we build upon the chromosome of the fittest individual of the previous phase. Thus the chromosome of the new individuals have the details of the chromosome of the fittest individual of the previous phase to which we concatenate new information(the parameters mentioned above) with randomly initialised values.</p>
